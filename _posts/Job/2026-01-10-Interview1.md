---
title: "Preparing ML/DL interview"
date: 2026-01-10
toc: true
toc_sticky: true
use_math: true
categories:
  - job
---

# 1. Training data and testing data in the context of machine learning.
## Answer

<details>
  <summary>Korean</summary>
  
  <div markdown="1">

  Training data는 머신러닝 알고리즘이 패턴을 학습하는 데 사용하는 데이터의 부분을 의미합니다. 예를 들어, 로지스틱 회귀 알고리즘의 파라미터는 훈련 데이터셋에서의 에러를 최소화하도록 선택될 수 있습니다. 반면 testing data는 알고리즘이 실제로 학습 과정에서 보지 않은 데이터로, 오직 알고리즘의 성능을 평가하기 위한 용도로 사용됩니다.

  </div>
</details>

<details>
  <summary>English</summary>
  
  <div markdown="1">

  Absolutely. Training data generally refers to the portion of the data that a machine learning algorithm uses to learn patterns. For example, the parameters of a logistic regression algorithm can be chosen such that the error is minimized on the training set. The testing set is data that is not seen by the actual algorithm and is used purely to gauge the algorithm's performance.

  </div>
</details>

# 2. If you need to tune parameters, do you tune it on the training data? What do you do instead?
## Answer

<details>
  <summary>Korean</summary>
  
  <div markdown="1">

  일반적으로 이런 것들을 하이퍼파라미터라고 부릅니다.
  보통은 훈련 데이터의 일부를 떼어내서 validation set이라고 부르고,
  이 validation set에서의 성능을 최대화하도록 하이퍼파라미터를 튜닝합니다.

  </div>
</details>

<details>
  <summary>English</summary>
  
  <div markdown="1">

  Generally, those are called hyperparameters. What people typically do is take out a portion of the training data and call it a validation set. Then they tune those hyperparameters to maximize the performance on the validation set.

  </div>
</details>

# 3. Which dataset do you actually evaluate the final model on?
## Answer

<details>
  <summary>Korean</summary>
  
  <div markdown="1">

  일반적으로 최종 단계에서는 test dataset으로 평가합니다.
  Validation set은 하이퍼파라미터를 튜닝하는 데에만 사용해야 하며,
  알고리즘의 학습이나 하이퍼파라미터 결정에 전혀 사용되지 않는
  완전히 분리된 holdout set을 유지하는 것이 중요합니다.

  </div>
</details>

<details>
  <summary>English</summary>
  
  <div markdown="1">

  Typically, you evaluate it on your test dataset at the final step. You should only be using your validation set to tune hyperparameters, and you should have a holdout set that never has any information used to inform the learning of the algorithm or the hyperparameters.

  </div>
</details>

# 4. Could you tell me about the differences between batch gradient descent, mini batch gradient descent, and stochastic gradient descent?

## Answer 

<details>
  <summary>Korean</summary>
  
  <div markdown="1">

  

  </div>
</details>

<details>
  <summary>English</summary>
  
  <div markdown="1">

  

  </div>
</details>

# 5. 왜 이런 서로 다른 gradient descent 방식들이 존재하나요? 언제 각각을 선택하나요?

# 6. 비볼록(non-convex) loss function의 경우, 이 최적화 알고리즘들이 global minimum에 도달하는 것이 보장되나요?

# 7. 모델이 local minimum에 도달하는 것은 문제가 되나요? 여전히 좋은 모델일 수 있나요?


